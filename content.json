{"meta":{"title":"Amy's Blog","subtitle":"","description":"","author":"Amy","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2021-11-08T10:30:31.000Z","updated":"2021-11-08T10:30:44.000Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-11-08T08:21:21.000Z","updated":"2021-11-08T08:22:04.000Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-11-08T11:00:59.000Z","updated":"2021-11-08T11:01:20.000Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-11-08T08:26:08.000Z","updated":"2021-11-08T08:26:40.000Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker的安装与使用教程（Ubuntu环境）","slug":"Docker的安装与使用教程（Ubuntu环境）","date":"2023-01-03T02:39:56.000Z","updated":"2023-01-03T09:11:39.458Z","comments":true,"path":"2023/01/03/Docker的安装与使用教程（Ubuntu环境）/","link":"","permalink":"http://example.com/2023/01/03/Docker%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%EF%BC%88Ubuntu%E7%8E%AF%E5%A2%83%EF%BC%89/","excerpt":"","text":"一、安装docker安装命令如下： 1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 测试docker是否安装成功： 1sudo docker help 若安装成功，终端会显示Usage: docker [OPTIONS] COMMAND，提示你输入更详细的docker命令。 二、配置镜像加速Docker 下载镜像时，如果不配置镜像加速，下载镜像会比较慢，常见的国内镜像加速地址包括： 12345678#腾讯云的镜像地址https://mirror.ccs.tencentyun.com #网易的镜像地址http://hub-mirror.c.163.com #阿里云的镜像地址https://&#123;自己的阿里云ID&#125;.mirror.aliyuncs.com 可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器： 12sudo mkdir -p /etc/dockersudo vim /etc/docker/daemon.json json文件输入以下内容，表示使用网易的镜像加速地址： 123&#123; &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;]&#125; 配置好镜像加速以后，需要重启docker服务： 12sudo systemctl daemon-reloadsudo systemctl restart docker 三、从docker hub拉取镜像docker hub类似github，不同的是github可以拉取工程代码、docker hub可以拉取镜像文件。使用之前，docker hub需要先在官网https://hub.docker.com/ 注册账号。 1234567891011# 搜索镜像sudo docker search ubuntuNAME DESCRIPTION STARS OFFICIAL AUTOMATEDubuntu Ubuntu is a Debian-based Linux operating sys… 15413 [OK] websphere-liberty WebSphere Liberty multi-architecture images … 291 [OK] ubuntu-upstart DEPRECATED, as is Upstart (find other proces… 112 [OK] neurodebian NeuroDebian provides neuroscience research s… 97 [OK] ubuntu/nginx Nginx, a high-performance reverse proxy &amp; we… 73 # 拉取镜像sudo docker pull ubuntu 四、常用的docker命令1、启动新容器 1sudo docker run --gpus all --shm-size 64G --name new_container -it -v /home/Documents:/usr/Documents yolov5_v1:latest bash –gpus all 代表使用本机所有的gpu, –shm-size 64G代表共享存储空间是64G，–name new_container代表本容器名为new_container，-v /home/Documents:/usr/Documents代表将本机的/home/Documents挂载到容器的/usr/Documents，yolov5_v1:latest是镜像名和版本号，可以理解为本容器是以镜像yolov5_v1:latest为基础建立的一个虚拟机。 2、启动并进入容器 12docker start container_ID #启动容器docker attach container_ID #进入容器 3、删除容器、删除镜像 12docker rm container_id # 删除容器docker rmi image_id # 删除镜像 4、查看容器 12docker ps -a # 查看所有容器docker ps # 查看所有正在运行的容器 5、查看所有镜像 1docker images # 查看镜像 6、从容器创建镜像 1sudo docker commit e1355f86c678 yolov5_v1:latest 7、导出镜像和导入镜像 12docker save -o yolov5_v1.tar yolov5_v1:latest # 导出镜像为tar压缩文件docker load --input yolov5_v1.tar # 从tar压缩文件导入镜像 五、常见的问题1、E: Unable to locate package sudo 的错误 解决方法：先运行apt-get update，再运行apt-get install sudo 2、缺少wget包 解决方法：sudo apt-get install wget 3、获取miniconda安装包，安装miniconda 12wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.shbash Miniconda3-py38_4.12.0-Linux-x86_64.sh 4、实时刷新gpu使用情况 123#1秒刷新1次watch -n 1 nvidia-smiwatch -n 1 --color gpustat --c","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Jetson Xavier NX刷机流程","slug":"Jetson Xavier NX刷机流程","date":"2022-12-31T03:53:56.000Z","updated":"2023-01-03T09:17:43.550Z","comments":true,"path":"2022/12/31/Jetson Xavier NX刷机流程/","link":"","permalink":"http://example.com/2022/12/31/Jetson%20Xavier%20NX%E5%88%B7%E6%9C%BA%E6%B5%81%E7%A8%8B/","excerpt":"","text":"一、配备刷机环境Jetson刷机需要使用Linux系统，可以是一台安装Linux操作系统的主机，也可以在一台Windows系统主机上安装Linux虚拟机。我选择的是安装VMWare WorkStation，在VM虚拟机中安装ubuntu系统。 二、Linux系统安装SDKManagerJetson刷机需要用到Nvidia的专用刷机软件SDKManger，到官网https://docs.nvidia.com/sdk-manager/ 下载(下载前需注册Nvidia的账号）。 三、Jetson烧录操作系统找到Jetson NX风扇下方的一排引脚，将第二个和第三个引脚（即GND和FC REC）用杜邦线短接，用USB线连接NX板和Linux电脑，给NX板接上电源。此时，Jetson NX进入烧录模式。 Step01：查看Target Hardware中Jetson NX是否连接好，按需选择JetPack版本和DeepStream版本，点击continue开始烧录。（Host Machine不用勾选，此项表示在linux主机上安装选中的包） Step02：选择Jetson OS，勾选接受协议，点击continue继续。（Jetson OS是开发板系统，Jetson SDK Components是cuda等组件，考虑到Jetson NX自带的存储空间是8G，暂时只烧录开发板系统，组件将烧录到SSD固态硬盘上） Step03：选择Manual Setup，OEM Configuration选择Runtime，点击Flash，后面只需要等待系统烧录完成，烧录过程比较漫长。 Step04：待系统烧录完成后，立即拔掉Jetson NX的电源线、拔掉USB线、拔掉第二引脚和第三引脚上的杜邦线。给Jetson NX重新接上电源线，接上显示器连接线，接上网线，接上键鼠无线接收器，在Jetson开机过程中，给Jetson系统设置时区、用户名、密码等必要的信息。如果Jetson能正常进入Ubuntu系统，桌面能看到L4T-README文件夹，表示系统烧录成功。 四、设置CSI相机的引脚Jetson NX自带两个CSI相机排线接口，就在电源孔后方，使用之前需要配置引脚。在Jetson NX上打开终端，运行 sudo /opt/nvidia/jetson-io/jetson-io.py，在弹出的界面上依次选择Configure Jetson Nano CSI Connector、Configure for compatible hardware、Camera XXX(选择自己的相机型号)、Save pin changes、Save and exit without rebooting。 此时，先关机，将CSI相机通过排线连到Jetson NX板上。开机后，在终端输入nvgstcapture，验证相机是否能取图。如果屏幕上出现相机实时图像，表示相机已成功连接。 五、设置从SSD固态硬盘启动系统因为Jetson NX本身存储空间有限，可以给开发板另外再装一个固态硬盘，开发板自带NvmeM.2接口。在Jetson NX关机状态下，装上SSD固态硬盘，开机。打开磁盘管理工具Disks,将磁盘工具格式化，并创建ext4分区。 利用命令行git clone https://github.com/jetsonhacks/rootOnNVMe.git 下载rootOnNVMe工具包。 进入rootOnNVMe文件夹，运行sh copy-rootfs-ssd.sh将系统文件复制到固态硬盘，再运行 sh setup-service.sh设置系统从SSD启动。 重启Jetson NX，查看Disks，如果Flilesystem Root是挂载在SSD固态硬盘上，表示系统已经是在SSD上启动。 六、安装Jetson SDK Components在Jetson NX终端输入ifconfig，查看板子的ip地址。 在Linux主机上再次打开SDK Manager，重复step01-step04，setp03勾选etson SDK Components（不要勾选Jetson OS），step04中connection选择Ethernet,填入Jetson NX的ip地址，用户名和密码，点击install，耐心等待cuda等组件安装完成。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Jetson","slug":"Jetson","permalink":"http://example.com/tags/Jetson/"}]},{"title":"YOLOV5实例分割：用TensorRT模型做推理加速","slug":"YOLOV5实例分割：用TensorRT模型做推理加速","date":"2022-12-16T11:12:50.000Z","updated":"2022-12-16T08:20:27.195Z","comments":true,"path":"2022/12/16/YOLOV5实例分割：用TensorRT模型做推理加速/","link":"","permalink":"http://example.com/2022/12/16/YOLOV5%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2%EF%BC%9A%E7%94%A8TensorRT%E6%A8%A1%E5%9E%8B%E5%81%9A%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/","excerpt":"","text":"yolov5官方工程的export.py支持将pytorch模型转换成engine模型，同时segment文件夹下的predict.py也支持TensorRT推理加速。本文是对官方工程的TensorRT推理过程做了提炼，可视化阶段要用到yolov5工程中的utils文件夹，建议在官方工程中测试使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158# yolov5的tensorrt推理from torchvision import transformsimport pycuda.autoinitimport numpy as npimport pycuda.driver as cudaimport tensorrt as trtimport cv2from PIL import Imageimport torchfrom utils.general import non_max_suppression, scale_boxesfrom utils.segment.general import process_mask, scale_imagefrom utils.plots import colors# 数据转换data_transform = transforms.Compose([ transforms.Resize([384, 640]), transforms.ToTensor()])def get_img_np_nchw(filename): img = Image.open(filename) if img.mode != &#x27;RGB&#x27;: img = img.convert(&#x27;RGB&#x27;) img = data_transform(img) img = np.expand_dims(img, 0).astype(np.float32) return img# Simple helper data class that&#x27;s a little nicer to use than a 2-tuple.class HostDeviceMem(object): def __init__(self, host_mem, device_mem): &quot;&quot;&quot;Within this context, host_mom means the cpu memory and device means the GPU memory &quot;&quot;&quot; self.host = host_mem self.device = device_mem def __str__(self): return &quot;Host:\\n&quot; + str(self.host) + &quot;\\nDevice:\\n&quot; + str(self.device) def __repr__(self): return self.__str__()# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.def allocate_buffers(engine, img_np_nchw): inputs = [] outputs = [] bindings = [] stream = cuda.Stream() for binding in engine: binding_shape = engine.get_binding_shape(binding) if binding_shape[-1] == -1: binding_shape[-2], binding_shape[-1] = img_np_nchw.shape[2:] size = trt.volume(binding_shape) * engine.max_batch_size dtype = trt.nptype(engine.get_binding_dtype(binding)) # Allocate host and device buffers host_mem = cuda.pagelocked_empty(size, dtype) device_mem = cuda.mem_alloc(host_mem.nbytes) # Append the device buffer to device bindings. bindings.append(int(device_mem)) # Append to the appropriate list. if engine.binding_is_input(binding): inputs.append(HostDeviceMem(host_mem, device_mem)) else: outputs.append(HostDeviceMem(host_mem, device_mem)) return inputs, outputs, bindings, stream# This function is generalized for multiple inputs/outputs.# inputs and outputs are expected to be lists of HostDeviceMem objects.def do_inference(context, bindings, inputs, outputs, stream, batch_size=1): # Transfer data from CPU to the GPU. [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs] # Run inference. context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle) # Transfer predictions back from the GPU. [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs] # Synchronize the stream stream.synchronize() # Return only the host outputs. return [out.host for out in outputs]def postprocess_the_outputs(trt_outputs): pred = trt_outputs[1].reshape(1, 15120, 117) proto = trt_outputs[0].reshape(1, 32, 96, 160) return pred, protofilename = &#x27;./data/images/zidane.jpg&#x27;# 图像预处理img_np_nchw = get_img_np_nchw(filename)print(&#x27;preprocess:&#x27;, img_np_nchw.shape)# 加载engineENGINE_PATH = &#x27;D:/PycharmProjects/yolov5-7.0/yolov5s-seg.engine&#x27;trt_logger = trt.Logger(trt.Logger.INFO)runtime = trt.Runtime(trt_logger)with open(ENGINE_PATH, &quot;rb&quot;) as f: engine = runtime.deserialize_cuda_engine(f.read())# 分配内存inputs, outputs, bindings, stream = allocate_buffers(engine, img_np_nchw) # input, output: host # bindingsinputs[0].host = img_np_nchw.reshape(-1)# 引擎定义输入尺寸context = engine.create_execution_context()if context.get_binding_shape(0)[-1] == -1: context.set_binding_shape(0, img_np_nchw.shape)trt_outputs = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream) # numpy datapred, proto = postprocess_the_outputs(trt_outputs)pred = torch.from_numpy(pred).to(&quot;cuda:0&quot;)proto = torch.from_numpy(proto).to(&quot;cuda:0&quot;)# NMSpred = non_max_suppression(pred, conf_thres=0.55, iou_thres=0.45, max_det=1000, nm=32)# 画图det = pred[0]masks = process_mask(proto[0], det[:, 6:], det[:, :4], img_np_nchw.shape[2:], upsample=True) # HWC# 画maskori_img = cv2.imread(filename)img = torch.from_numpy(img_np_nchw).to(&quot;cuda:0&quot;)if len(masks) == 0: dst_img = img[0].permute(1, 2, 0).contiguous().cpu().numpy() * 255colors = [colors(x, True) for x in det[:, 5]]colors = torch.tensor(colors, device=&quot;cuda:0&quot;, dtype=torch.float32) / 255.0colors = colors[:, None, None] # shape(n,1,1,3)masks = masks.unsqueeze(3) # shape(n,h,w,1)masks_color = masks * (colors * 0.5) # shape(n,h,w,3)inv_alph_masks = (1 - masks * 0.5).cumprod(0) # shape(n,h,w,1)mcs = (masks_color * inv_alph_masks).sum(0) * 2 # mask color summand shape(n,h,w,3)dst_img = img[0].flip(dims=[0]) # flip channeldst_img = dst_img.permute(1, 2, 0).contiguous() # shape(h,w,3)dst_img = dst_img * inv_alph_masks[-1] + mcsim_mask = (dst_img * 255).byte().cpu().numpy()dst_img = scale_image(dst_img.shape, im_mask, ori_img.shape)# 画box label scoredet[:, :4] = scale_boxes(img.shape[2:], det[:, :4], ori_img.shape).round() # rescale boxes to ori_img sizedet_cpu = pred[0].cpu().numpy()for i, item in enumerate(det_cpu): # 画box box_int = item[0:4].astype(np.int32) cv2.rectangle(dst_img, (box_int[0], box_int[1]), (box_int[2], box_int[3]), color=(0, 255, 0), thickness=1) # 画label label = item[5] score = item[4] org = (min(box_int[0], box_int[2]), min(box_int[1], box_int[3]) - 8) text = &#x27;&#123;&#125;--&#123;:.2f&#125;&#x27;.format(int(label), score) cv2.putText(dst_img, text, org=org, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=1)cv2.imshow(&#x27;result&#x27;, dst_img)cv2.waitKey()cv2.imwrite(&#x27;out2.jpg&#x27;, dst_img) 推理结果图：代码运行环境： TensorRT版本’8.2.3’ torch版本’1.8.1+cu111’ trt模型输入尺寸（384, 640）","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"}]},{"title":"YOLOV5-7.0实例分割onnx模型推理简化流程","slug":"YOLOV5-7.0实例分割onnx模型推理简化流程","date":"2022-12-15T12:22:32.000Z","updated":"2022-12-15T14:10:58.000Z","comments":true,"path":"2022/12/15/YOLOV5-7.0实例分割onnx模型推理简化流程/","link":"","permalink":"http://example.com/2022/12/15/YOLOV5-7.0%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2onnx%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E7%AE%80%E5%8C%96%E6%B5%81%E7%A8%8B/","excerpt":"","text":"yolov5官方工程包含训练、推理、部署等众多代码，本文针对onnx模型的推理代码做了简化。代码需要依赖官方工程的utils包（即utils文件夹），建议在官方工程里测试使用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# yolov5-7.0 onnx模型推理简化流程import torchimport cv2import numpy as npfrom copy import deepcopyimport onnxruntime as ortfrom utils.general import non_max_suppression, scale_boxesfrom utils.augmentations import letterboxfrom utils.segment.general import masks2segments, process_mask, scale_imagefrom utils.plots import colorsmodel_path = &quot;D:/PycharmProjects/yolov5-7.0/yolov5s-seg.onnx&quot;img_path = &quot;./data/images/zidane.jpg&quot;# 数据预处理img = cv2.imread(img_path)print(&#x27;ori_img:&#x27;, img.shape)ori_img = deepcopy(img)img = letterbox(img, new_shape=(640, 640), stride=32, auto=True)[0] # padded resizeimg = np.ascontiguousarray(img.transpose((2, 0, 1))[::-1]) # HWC to CHW, BGR to RGB,contiguous# img = torch.from_numpy(img).to(&quot;cuda:0&quot;) # ndarray to tensor# img = img.float() # uint8 to fp32img = img.astype(np.float32)img = img / 255 # 0 - 255 to 0.0 - 1.0if len(img.shape) == 3: img = img[None] # expand for batch dim# 加载模型sess = ort.InferenceSession(model_path, providers=[&#x27;CUDAExecutionProvider&#x27;]) # &#x27;CPUExecutionProvider&#x27;input_name = sess.get_inputs()[0].nameoutput_name = [output.name for output in sess.get_outputs()]# 推理outputs = sess.run(output_name, &#123;input_name: img&#125;)pred, proto = outputs[0:2]pred = torch.from_numpy(pred).to(&quot;cuda:0&quot;)proto = torch.from_numpy(proto).to(&quot;cuda:0&quot;)# NMSpred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, max_det=1000, nm=32)# 画图print(&#x27;resize_img:&#x27;, img.shape)det = pred[0]masks = process_mask(proto[0], det[:, 6:], det[:, :4], img.shape[2:], upsample=True) # HWC# 画maskimg = torch.from_numpy(img).to(&quot;cuda:0&quot;)if len(masks) == 0: dst_img = img[0].permute(1, 2, 0).contiguous().cpu().numpy() * 255colors = [colors(x, True) for x in det[:, 5]]colors = torch.tensor(colors, device=&quot;cuda:0&quot;, dtype=torch.float32) / 255.0colors = colors[:, None, None] # shape(n,1,1,3)masks = masks.unsqueeze(3) # shape(n,h,w,1)masks_color = masks * (colors * 0.5) # shape(n,h,w,3)inv_alph_masks = (1 - masks * 0.5).cumprod(0) # shape(n,h,w,1)mcs = (masks_color * inv_alph_masks).sum(0) * 2 # mask color summand shape(n,h,w,3)dst_img = img[0].flip(dims=[0]) # flip channeldst_img = dst_img.permute(1, 2, 0).contiguous() # shape(h,w,3)dst_img = dst_img * inv_alph_masks[-1] + mcsim_mask = (dst_img * 255).byte().cpu().numpy()dst_img = scale_image(dst_img.shape, im_mask, ori_img.shape)# 画box label scoredet[:, :4] = scale_boxes(img.shape[2:], det[:, :4], ori_img.shape).round() # rescale boxes to ori_img sizedet_cpu = pred[0].cpu().numpy()for i, item in enumerate(det_cpu): # 画box box_int = item[0:4].astype(np.int32) cv2.rectangle(dst_img, (box_int[0], box_int[1]), (box_int[2], box_int[3]), color=(0, 255, 0), thickness=1) # 画label label = item[5] score = item[4] org = (min(box_int[0], box_int[2]), min(box_int[1], box_int[3]) - 8) text = &#x27;&#123;&#125;|&#123;:.2f&#125;&#x27;.format(int(label), score) cv2.putText(dst_img, text, org=org, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=1)cv2.imshow(&#x27;result&#x27;, dst_img)cv2.waitKey()cv2.imwrite(&#x27;out.jpg&#x27;, dst_img) 推理结果图如下：","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"}]},{"title":"YOLOV5-7.0实例分割pt模型推理简化流程","slug":"YOLOV5-7.0实例分割pt模型推理简化流程","date":"2022-12-14T11:15:25.000Z","updated":"2022-12-15T14:09:48.000Z","comments":true,"path":"2022/12/14/YOLOV5-7.0实例分割pt模型推理简化流程/","link":"","permalink":"http://example.com/2022/12/14/YOLOV5-7.0%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2pt%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E7%AE%80%E5%8C%96%E6%B5%81%E7%A8%8B/","excerpt":"","text":"yolov5官方工程包含训练、推理、部署等众多代码，本文针对pt模型的推理代码做了简化。代码需要依赖官方工程的utils包（即utils文件夹），建议在官方工程里测试使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# yolov5-7.0 pt模型推理简化流程import torchimport cv2import numpy as npfrom copy import deepcopyfrom utils.general import non_max_suppression, scale_boxesfrom utils.augmentations import letterboxfrom utils.segment.general import process_mask, scale_imagefrom utils.plots import colorsmodel_path = &quot;D:/PycharmProjects/yolov5-7.0/yolov5s-seg.pt&quot;img_path = &quot;./data/images/zidane.jpg&quot;# 加载模型model = torch.load(model_path, map_location=&#x27;cpu&#x27;)model = (model.get(&#x27;ema&#x27;) or model[&#x27;model&#x27;]).to(&quot;cuda:0&quot;).float() # FP32 modelmodel.eval()# 数据预处理img = cv2.imread(img_path)print(&#x27;ori_img:&#x27;, img.shape)ori_img = deepcopy(img)img = letterbox(img, new_shape=(640, 640), stride=32, auto=True)[0] # padded resizeimg = np.ascontiguousarray(img.transpose((2, 0, 1))[::-1]) # HWC to CHW, BGR to RGB,contiguousimg = torch.from_numpy(img).to(&quot;cuda:0&quot;) # ndarray to tensorimg = img.float() # uint8 to fp32img = img / 255 # 0 - 255 to 0.0 - 1.0if len(img.shape) == 3: img = img[None] # expand for batch dim# 推理result = model(img, augment=False)pred, proto = result[0:2]# NMSpred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, max_det=1000, nm=32)# 画图print(&#x27;resize_img:&#x27;, img.shape)det = pred[0]masks = process_mask(proto[0], det[:, 6:], det[:, :4], img.shape[2:], upsample=True) # HWC# 画maskif len(masks) == 0: dst_img = img[0].permute(1, 2, 0).contiguous().cpu().numpy() * 255colors = [colors(x, True) for x in det[:, 5]]colors = torch.tensor(colors, device=&quot;cuda:0&quot;, dtype=torch.float32) / 255.0colors = colors[:, None, None] # shape(n,1,1,3)masks = masks.unsqueeze(3) # shape(n,h,w,1)masks_color = masks * (colors * 0.5) # shape(n,h,w,3)inv_alph_masks = (1 - masks * 0.5).cumprod(0) # shape(n,h,w,1)mcs = (masks_color * inv_alph_masks).sum(0) * 2 # mask color summand shape(n,h,w,3)dst_img = img[0].flip(dims=[0]) # flip channeldst_img = dst_img.permute(1, 2, 0).contiguous() # shape(h,w,3)dst_img = dst_img * inv_alph_masks[-1] + mcsim_mask = (dst_img * 255).byte().cpu().numpy()dst_img = scale_image(dst_img.shape, im_mask, ori_img.shape)# 画box label scoredet[:, :4] = scale_boxes(img.shape[2:], det[:, :4], ori_img.shape).round() # rescale boxes to ori_img sizedet_cpu = pred[0].cpu().numpy()for i, item in enumerate(det_cpu): # 画box box_int = item[0:4].astype(np.int32) cv2.rectangle(dst_img, (box_int[0], box_int[1]), (box_int[2], box_int[3]), color=(0, 255, 0), thickness=1) # 画label label = item[5] score = item[4] org = (min(box_int[0], box_int[2]), min(box_int[1], box_int[3]) - 8) text = &#x27;&#123;&#125;--&#123;:.2f&#125;&#x27;.format(int(label), score) cv2.putText(dst_img, text, org=org, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=1)cv2.imshow(&#x27;result&#x27;, dst_img)cv2.waitKey()cv2.imwrite(&#x27;out.jpg&#x27;, dst_img) 推理结果图如下：","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"}]},{"title":"如何修改onnx模型的batchsize和分类标签？","slug":"如何修改onnx模型的batchsize和分类标签","date":"2022-12-13T12:12:50.000Z","updated":"2022-12-15T14:05:50.000Z","comments":true,"path":"2022/12/13/如何修改onnx模型的batchsize和分类标签/","link":"","permalink":"http://example.com/2022/12/13/%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9onnx%E6%A8%A1%E5%9E%8B%E7%9A%84batchsize%E5%92%8C%E5%88%86%E7%B1%BB%E6%A0%87%E7%AD%BE/","excerpt":"","text":"有时候，我们用netron查看一个onnx模，发现其batchsize=1、输入数据的尺寸固定。这种情况下，onnx模型无法进行多图同时推理、也无法兼容动态输入数据。这时，我们可以通过简单的代码改写onnx模型： 1234567891011121314151617181920212223242526272829303132333435# onnx_to_n_batchsizeimport onnxdef change_input_dim(model, ): batch_size = &quot;16&quot; # The following code changes the first dimension of every input to be batch_size # Modify as appropriate ... note that this requires all inputs to # have the same batch_size inputs = model.graph.input for input in inputs: # Checks omitted.This assumes that all inputs are tensors and have a shape with first dim. # Add checks as needed. dim1 = input.type.tensor_type.shape.dim[0] # update dim to be a symbolic value if isinstance(batch_size, str): # set dynamic batch size dim1.dim_param = batch_size elif (isinstance(batch_size, str) and batch_size.isdigit()) or isinstance(batch_size, int): # set given batch size dim1.dim_value = int(batch_size) else: # set batch size of 1 dim1.dim_value = 1def apply(transform, infile, outfile): model = onnx.load(infile) transform(model, ) onnx.save(model, outfile)apply(change_input_dim, &#x27;C:/mmdeploy/work_dir_onnx/end2end-sim.onnx&#x27;, &#x27;C:/mmdeploy/work_dir_onnx/end2end-sim-16input.onnx&#x27;) 以上代码中，batch_size等于数字时新onnx模型的batch_size变成相应的值，batch_size=”n”时新onnx模型的batch_size是动态的。 一个onnx模型的分类标签有可能全是中文，有时候我们需要将标签转换为英文，这时，我们可以通过简单的代码改写onnx模型： 123456789101112# onnx模型更新缺陷类别import onnxonnx_model = onnx.load(&#x27;D:/PycharmProjects/yolov5-7.0/runs/train-seg/exp/weights/best.onnx&#x27;)category_list = [&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;10&#x27;, &#x27;11&#x27;, &#x27;12&#x27;]old_model_names = onnx_model.metadata_props[-1].valueprint(&#x27;old_model_names:&#x27;, old_model_names)onnx_model.metadata_props[-1].value = str(category_list).encode(&#x27;utf-8&#x27;)onnx.save(onnx_model, &#x27;best-new.onnx&#x27;)new_model = onnx.load(&#x27;best-new.onnx&#x27;)new_model_names = onnx_model.metadata_props[-1].valueprint(&#x27;new_model_names:&#x27;, new_model_names) 代码运行结果： 12old_model_names: &#123;0: &#x27;person&#x27;, 1: &#x27;bicycle&#x27;, 2: &#x27;car&#x27;, 3: &#x27;motorcycle&#x27;, 4: &#x27;airplane&#x27;, 5: &#x27;bus&#x27;, 6: &#x27;train&#x27;, 7: &#x27;truck&#x27;, 8: &#x27;boat&#x27;, 9: &#x27;traffic light&#x27;, 10: &#x27;fire hydrant&#x27;, 11: &#x27;stop sign&#x27;, 12: &#x27;parking meter&#x27;, 13: &#x27;bench&#x27;, 14: &#x27;bird&#x27;, 15: &#x27;cat&#x27;, 16: &#x27;dog&#x27;, 17: &#x27;horse&#x27;, 18: &#x27;sheep&#x27;, 19: &#x27;cow&#x27;, 20: &#x27;elephant&#x27;, 21: &#x27;bear&#x27;, 22: &#x27;zebra&#x27;, 23: &#x27;giraffe&#x27;, 24: &#x27;backpack&#x27;, 25: &#x27;umbrella&#x27;, 26: &#x27;handbag&#x27;, 27: &#x27;tie&#x27;, 28: &#x27;suitcase&#x27;, 29: &#x27;frisbee&#x27;, 30: &#x27;skis&#x27;, 31: &#x27;snowboard&#x27;, 32: &#x27;sports ball&#x27;, 33: &#x27;kite&#x27;, 34: &#x27;baseball bat&#x27;, 35: &#x27;baseball glove&#x27;, 36: &#x27;skateboard&#x27;, 37: &#x27;surfboard&#x27;, 38: &#x27;tennis racket&#x27;, 39: &#x27;bottle&#x27;, 40: &#x27;wine glass&#x27;, 41: &#x27;cup&#x27;, 42: &#x27;fork&#x27;, 43: &#x27;knife&#x27;, 44: &#x27;spoon&#x27;, 45: &#x27;bowl&#x27;, 46: &#x27;banana&#x27;, 47: &#x27;apple&#x27;, 48: &#x27;sandwich&#x27;, 49: &#x27;orange&#x27;, 50: &#x27;broccoli&#x27;, 51: &#x27;carrot&#x27;, 52: &#x27;hot dog&#x27;, 53: &#x27;pizza&#x27;, 54: &#x27;donut&#x27;, 55: &#x27;cake&#x27;, 56: &#x27;chair&#x27;, 57: &#x27;couch&#x27;, 58: &#x27;potted plant&#x27;, 59: &#x27;bed&#x27;, 60: &#x27;dining table&#x27;, 61: &#x27;toilet&#x27;, 62: &#x27;tv&#x27;, 63: &#x27;laptop&#x27;, 64: &#x27;mouse&#x27;, 65: &#x27;remote&#x27;, 66: &#x27;keyboard&#x27;, 67: &#x27;cell phone&#x27;, 68: &#x27;microwave&#x27;, 69: &#x27;oven&#x27;, 70: &#x27;toaster&#x27;, 71: &#x27;sink&#x27;, 72: &#x27;refrigerator&#x27;, 73: &#x27;book&#x27;, 74: &#x27;clock&#x27;, 75: &#x27;vase&#x27;, 76: &#x27;scissors&#x27;, 77: &#x27;teddy bear&#x27;, 78: &#x27;hair drier&#x27;, 79: &#x27;toothbrush&#x27;&#125;new_model_names: [&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;10&#x27;, &#x27;11&#x27;, &#x27;12&#x27;]","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"}]},{"title":"用netron查看深度学习模型的网络结构","slug":"用netron查看深度学习模型的网络结构","date":"2022-12-12T13:53:56.000Z","updated":"2022-12-15T14:05:58.000Z","comments":true,"path":"2022/12/12/用netron查看深度学习模型的网络结构/","link":"","permalink":"http://example.com/2022/12/12/%E7%94%A8netron%E6%9F%A5%E7%9C%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/","excerpt":"","text":"netron是个好东西。 以上图onnx模型为例：你能看到模型的stride、names、inputs、outputs，等于你知道了模型训练时的填充步幅、分类的类别名称、输入数据的格式、输出数据的格式，有助于初步了解模型、后期解析模型推理结果。 想要详细了解模型网络结构的，能看着netron结构图一步步研究。想做模型裁剪的，做完裁剪能用netron直观看到裁剪效果。更多用法，靠自己挖掘了…… 关键是，用起来省事啊，随便打开一个浏览器，搜索netron或者输入网址https://netron.app/ 即可打开netron","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"}]},{"title":"YOLOV5-7.0实例分割pth模型转onnx模型","slug":"YOLOV5-7.0实例分割pth模型转onnx模型","date":"2022-12-11T13:12:49.000Z","updated":"2022-12-15T13:24:14.000Z","comments":true,"path":"2022/12/11/YOLOV5-7.0实例分割pth模型转onnx模型/","link":"","permalink":"http://example.com/2022/12/11/YOLOV5-7.0%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2pth%E6%A8%A1%E5%9E%8B%E8%BD%AConnx%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"pytorch模型要转换成onnx模型，基本流程主要是两步：第一，加载模型结构；第二，利用torch.onnx.export进行转换。yolov5训练好的实例分割模型，原始格式是pth，转换成onnx模型的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# pt模型转onnximport torchimport onnximport sys# 导入yolov5所在的路径，模型转换需要yolov5工程定义的网络结构（即models、utils两个文件夹）sys.path.insert(0, &#x27;D:/PycharmProjects/yolov5-7.0/&#x27;)model_path = &quot;D:/PycharmProjects/yolov5-7.0/runs/train-seg/exp/weights/best.pt&quot;onnx_path = &quot;D:/PycharmProjects/yolov5-7.0/runs/train-seg/exp/weights/best.onnx&quot;model = torch.load(model_path, map_location=&#x27;cpu&#x27;)model = (model.get(&#x27;ema&#x27;) or model[&#x27;model&#x27;]).float()if hasattr(model, &#x27;fuse&#x27;): model.fuse().eval()else: model.eval()# 设置export为true，裁剪不必要的输出for k, m in model.named_modules(): if str(type(m)) == &quot;&lt;class &#x27;models.yolo.Segment&#x27;&gt;&quot;: m.export = True# Input to the modelx = torch.randn(1, 3, 640, 640, requires_grad=True)# Export the modeltorch.onnx.export(model, # model being run x, # model input onnx_path, opset_version=12, # the ONNX version to export the model to do_constant_folding=True, # 是否执行常量折叠优化 input_names=[&#x27;input&#x27;], # the model&#x27;s input names output_names=[&#x27;output0&#x27;, &#x27;output1&#x27;], # the model&#x27;s output names dynamic_axes=&#123;&#x27;input&#x27;: &#123;0: &#x27;batch&#x27;, 2: &#x27;height&#x27;, 3: &#x27;width&#x27;&#125;, &#x27;output0&#x27;: &#123;0: &#x27;batch&#x27;, 1: &#x27;anchors&#x27;&#125;, &#x27;output1&#x27;: &#123;0: &#x27;batch&#x27;, 2: &#x27;mask_height&#x27;, 3: &#x27;mask_width&#x27;&#125;&#125; )# Checksmodel_onnx = onnx.load(onnx_path) # load onnx modelonnx.checker.check_model(model_onnx) # check onnx model# Metadatad = &#123;&#x27;stride&#x27;: int(max(model.stride)), &#x27;names&#x27;: model.names&#125;for k, v in d.items(): meta = model_onnx.metadata_props.add() meta.key, meta.value = k, str(v)onnx.save(model_onnx, onnx_path)print(&#x27;process over !!!&#x27;)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"}]},{"title":"井字棋小游戏","slug":"ticTacToe","date":"2021-11-05T12:25:32.000Z","updated":"2022-12-16T01:45:55.621Z","comments":true,"path":"2021/11/05/ticTacToe/","link":"","permalink":"http://example.com/2021/11/05/ticTacToe/","excerpt":"","text":"本系列是学习《automate the boring stuff with python》这本书的学习笔记。 一个小程序：井字棋123456789101112131415161718192021theBoard = &#123; &#x27;top-L&#x27;: &#x27; &#x27;, &#x27;top-M&#x27;: &#x27; &#x27;, &#x27;top-R&#x27;: &#x27; &#x27;, &#x27;mid-L&#x27;: &#x27; &#x27;, &#x27;mid-M&#x27;: &#x27; &#x27;, &#x27;mid-R&#x27;: &#x27; &#x27;, &#x27;low-L&#x27;: &#x27; &#x27;, &#x27;low-M&#x27;: &#x27; &#x27;, &#x27;low-R&#x27;: &#x27; &#x27;&#125;def printBoard(board): print(board[&#x27;top-L&#x27;] + &#x27;|&#x27; + board[&#x27;top-M&#x27;] + &#x27;|&#x27; + board[&#x27;top-R&#x27;]) print(&#x27;-+-+-&#x27;) print(board[&#x27;mid-L&#x27;] + &#x27;|&#x27; + board[&#x27;mid-M&#x27;] + &#x27;|&#x27; + board[&#x27;mid-R&#x27;]) print(&#x27;-+-+-&#x27;) print(board[&#x27;low-L&#x27;] + &#x27;|&#x27; + board[&#x27;low-M&#x27;] + &#x27;|&#x27; + board[&#x27;low-R&#x27;])turn = &#x27;X&#x27;for i in range(9): printBoard(theBoard) print(&#x27;Turn for &#x27; + turn + &#x27;. Move on which space?&#x27;) move = input() theBoard[move] = turn if turn == &#x27;X&#x27;: turn = &#x27;O&#x27; else: turn = &#x27;X&#x27;printBoard(theBoard) 程序运行结果123456789101112 | | -+-+- | | -+-+- | | Turn for X. Move on which space?mid-M | | -+-+- |X| -+-+- | |","categories":[{"name":"简单编程","slug":"简单编程","permalink":"http://example.com/categories/%E7%AE%80%E5%8D%95%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"小游戏","slug":"小游戏","permalink":"http://example.com/tags/%E5%B0%8F%E6%B8%B8%E6%88%8F/"}]},{"title":"猜数字小游戏","slug":"guess-the-number","date":"2021-11-05T12:22:32.000Z","updated":"2022-12-16T01:45:09.994Z","comments":true,"path":"2021/11/05/guess-the-number/","link":"","permalink":"http://example.com/2021/11/05/guess-the-number/","excerpt":"","text":"本系列是学习《automate the boring stuff with python》这本书的学习笔记。 一个小程序：猜数字1234567891011121314151617181920# 这是一个猜数字的小游戏。import randomsecretNumber = random.randint(1, 20)print(&#x27;I am thinking of a number between 1 and 20.&#x27;)# 让玩游戏的人猜6次数字。 for guessesTaken in range(1, 7): print(&#x27;Take a guess.&#x27;) guess = int(input()) if guess &lt; secretNumber: print(&#x27;Your guess is too low.&#x27;) elif guess &gt; secretNumber: print(&#x27;Your guess is too high.&#x27;) else: break # This condition is the correct guess!if guess == secretNumber: print(&#x27;Good job! You guessed my number in &#x27; + str(guessesTaken) + &#x27; guesses!&#x27;)else: print(&#x27;Nope. The number I was thinking of was &#x27; + str(secretNumber)) 程序运行结果12345678910I am thinking of a number between 1 and 20. Take a guess.10Your guess is too low.Take a guess.15Your guess is too low. Take a guess.17Your guess is too high. Take a guess.16Good job! You guessed my number in 4 guesses!","categories":[{"name":"简单编程","slug":"简单编程","permalink":"http://example.com/categories/%E7%AE%80%E5%8D%95%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"小游戏","slug":"小游戏","permalink":"http://example.com/tags/%E5%B0%8F%E6%B8%B8%E6%88%8F/"}]},{"title":"my first blog","slug":"my-first-blog","date":"2021-11-01T03:12:49.000Z","updated":"2022-12-15T13:22:04.000Z","comments":true,"path":"2021/11/01/my-first-blog/","link":"","permalink":"http://example.com/2021/11/01/my-first-blog/","excerpt":"","text":"","categories":[{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"个人","slug":"个人","permalink":"http://example.com/tags/%E4%B8%AA%E4%BA%BA/"}]}],"categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"简单编程","slug":"简单编程","permalink":"http://example.com/categories/%E7%AE%80%E5%8D%95%E7%BC%96%E7%A8%8B/"},{"name":"生活","slug":"生活","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"},{"name":"Jetson","slug":"Jetson","permalink":"http://example.com/tags/Jetson/"},{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"小游戏","slug":"小游戏","permalink":"http://example.com/tags/%E5%B0%8F%E6%B8%B8%E6%88%8F/"},{"name":"个人","slug":"个人","permalink":"http://example.com/tags/%E4%B8%AA%E4%BA%BA/"}]}